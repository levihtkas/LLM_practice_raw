{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc5ede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a12531",
   "metadata": {},
   "outputs": [],
   "source": [
    "anthropic_url = \"https://api.anthropic.com/v1/\"\n",
    "gemini_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "grok_url = \"https://api.x.ai/v1\"\n",
    "groq_url = \"https://api.groq.com/openai/v1\"\n",
    "ollama_url = \"http://localhost:11434/v1\"\n",
    "openrouter_url = \"https://openrouter.ai/api/v1\"\n",
    "\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "\n",
    "models = [\"gpt-5\", \"claude-sonnet-4-5-20250929\" ]\n",
    "\n",
    "openai= OpenAI(api_key=openai_api_key)\n",
    "anthropic = OpenAI(base_url=anthropic_url,api_key=anthropic_api_key)\n",
    "clients = {\"gpt-5\": openai, \"claude-sonnet-4-5-20250929\": anthropic}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05220755",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You will be given a python code convert to an Pytorch code both will run in CPUs only. I want no additional text other then the code explain anthing you want in the comments\n",
    "\"\"\"\n",
    "\n",
    "def user_prompt_for(python):\n",
    "  return f\"\"\"\n",
    "  Here is my python code {python} to be converted give the resultant pytorch code with code to see how much time it takes to run\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eed9f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6479a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(python):\n",
    "  return [{'role':'user','content':user_prompt_for(python)},{'role':'system','content':system_prompt}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3ad3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def port(model,python):\n",
    "  client = clients[model]\n",
    "  response = client.chat.completions.create(model=model,messages=messages_for(python))\n",
    "  reply = response.choices[0].message.content\n",
    "  reply = reply.replace('```python','').replace('```','')\n",
    "  return reply\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326ab825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import contextlib\n",
    "def run_pythons(code):\n",
    "  buffer = io.StringIO()\n",
    "  with contextlib.redirect_stdout(buffer):\n",
    "        exec(code)\n",
    "  return buffer.getvalue()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92fd244",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = \"\"\"\n",
    "import time\n",
    "\n",
    "def calculate(iterations, param1, param2):\n",
    "    result = 1.0\n",
    "    for i in range(1, iterations+1):\n",
    "        j = i * param1 - param2\n",
    "        result -= (1/j)\n",
    "        j = i * param1 + param2\n",
    "        result += (1/j)\n",
    "    return result\n",
    "\n",
    "start_time = time.time()\n",
    "result = calculate(200_000_000, 4, 1) * 4\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Result: {result:.12f}\")\n",
    "print(f\"Execution Time: {(end_time - start_time):.6f} seconds\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81932df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks() as ui:\n",
    "  with gr.Row():\n",
    "    python = gr.Code(label = \"Python code: \",lines=28,value=pi)\n",
    "    pytorch = gr.Code(label=\"Pytorch code: \",lines=28)\n",
    "  with gr.Row():\n",
    "    model = gr.Dropdown(models,label=\"Select model\",value=models[0])\n",
    "    convert = gr.Button(\"Convert code\")\n",
    "  with gr.Row():\n",
    "    run_python = gr.Button(\"Run Python\")\n",
    "    run_pytorch = gr.Button(\"Run Pytorch\")\n",
    "  with gr.Row():\n",
    "    python_out = gr.TextArea(label=\"Python\",lines=8)\n",
    "    py_out = gr.TextArea(label=\"Pytorch\",lines=8)\n",
    "  run_python.click(run_pythons,inputs=[python],outputs=[python_out])\n",
    "  run_pytorch.click(run_pythons,inputs=[python],outputs=[py_out])\n",
    "  convert.click(port,inputs=[model,python],outputs=[pytorch])\n",
    "ui.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48feb988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f8ac6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
