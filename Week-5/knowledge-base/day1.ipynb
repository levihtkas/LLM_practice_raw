{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cf54d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "from pathlib import Path\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1910d2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "open_ai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model = \"gpt-4.1-nano\"\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cc6642",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge = {}\n",
    "\n",
    "filenames = glob.glob(\"./employees/*\")\n",
    "\n",
    "for filename in filenames:\n",
    "  name = Path(filename).stem.split(' ')[-1]\n",
    "  with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "    knowledge[name.lower()] = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64535cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57676be",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge['lancaster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80901952",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob(\"./products/*\")\n",
    "\n",
    "for file in filenames:\n",
    "  name = Path(file).stem.split(\" \")[-1]\n",
    "  with open(file,'r',encoding = \"utf-8\") as f:\n",
    "    knowledge[name] = f.read() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e351441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3453e900",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PREFIX = \"\"\"\n",
    "You represent Insurellm, the Insurance Tech company.\n",
    "You are an expert in answering questions about Insurellm; its employees and its products.\n",
    "You are provided with additional context that might be relevant to the user's question.\n",
    "Give brief, accurate answers. If you don't know the answer, say so.\n",
    "\n",
    "Relevant context:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6937a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relavant_context_simple(message):\n",
    "  message_arr = message.split()\n",
    "  message_cleaned = [msg for msg in message_arr if msg.isalpha or msg.isspace]\n",
    "  context = [knowledge[msg] for msg in message_cleaned if msg in knowledge]\n",
    "  return context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227e96da",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaee5030",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display,Markdown\n",
    "Markdown(get_relavant_context_simple(\"thomson\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3d880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def additonal_context(message):\n",
    "  releavant_context= get_relavant_context_simple(message)\n",
    "  if not releavant_context:\n",
    "    result = \"No additional info is found about this information\"\n",
    "  else :\n",
    "    result = \"Following info might be useful\"\n",
    "    result = \"\\n \".join(releavant_context)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4491c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "additonal_context(\"thomson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d5fca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In gradio we often use chat with message and history so here it goes\n",
    "\n",
    "def chat(message,history):\n",
    "  system_message = SYSTEM_PREFIX + additonal_context(message)\n",
    "  print(history)\n",
    "  messages = [{\"role\":'system','content':system_message}] + history + [{'role':'user','content':message}]\n",
    "  response = openai.chat.completions.create(model=model,messages=messages)\n",
    "  return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a855442",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = gr.ChatInterface(chat).launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca5069f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
