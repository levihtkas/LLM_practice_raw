{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcb305a0",
   "metadata": {},
   "source": [
    "GRADIO Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58904cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec71395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf082747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556e96b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29152ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()\n",
    "anthropic_url = \"https://api.anthropic.com/v1/\"\n",
    "gemini_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "anthropic = OpenAI(api_key=anthropic_api_key, base_url=anthropic_url)\n",
    "gemini = OpenAI(api_key=google_api_key, base_url=gemini_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56682ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's wrap a call to GPT-4.1-mini in a simple function\n",
    "\n",
    "system_message = \"You are a helpful assistant\"\n",
    "\n",
    "def message_gpt(prompt):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}, {\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4.1-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed74c019",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_gpt(\"Hey How intelligent have LLMs become could they create end to end softwware\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d50267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's a simple function\n",
    "\n",
    "def shout(text):\n",
    "    print(f\"Shout has been called with input {text}\")\n",
    "    return text.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baed107a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.Interface(fn=shout,inputs=\"textbox\",outputs=\"textbox\",flagging_mode='never').launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2dcb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030a91c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.Interface(fn=shout,inputs=\"textbox\",outputs=\"textbox\",flagging_mode=\"never\").launch(inbrowser=True,auth=(\"auth\",\"122\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428d4863",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_input = gr.Textbox(label=\"You message: \",info=\"Enter a message to be shouted\",lines=7)\n",
    "\n",
    "message_output = gr.Textbox(label=\"Response: \",lines=8)\n",
    "\n",
    "gr.Interface(\n",
    "  fn=shout,\n",
    "  inputs = [message_input],\n",
    "  outputs=[message_output],\n",
    "  examples=[\"Hello\",\"kfrosd\"],\n",
    "  title=\"SHOUT\",\n",
    "  flagging_mode='never'\n",
    ").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e97558",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_input = gr.Textbox(label=\"You message: \",info=\"Enter a message to be chatted\",lines=7)\n",
    "\n",
    "message_output = gr.Textbox(label=\"Response: \",lines=8)\n",
    "\n",
    "gr.Interface(\n",
    "  fn=message_gpt,\n",
    "  inputs = [message_input],\n",
    "  outputs=[message_output],\n",
    "  examples=[\"Hello\",\"kfrosd\"],\n",
    "  title=\"SHOUT\",\n",
    "  flagging_mode='never'\n",
    ").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cbd12f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e266fe33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ba7eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant that responds in markdown without code blocks\"\n",
    "\n",
    "message_input = gr.Textbox(label=\"Your message:\", info=\"Enter a message for GPT-4.1-mini\", lines=7)\n",
    "message_output = gr.Markdown(label=\"Response:\")\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=message_gpt,\n",
    "    title=\"GPT\", \n",
    "    inputs=[message_input], \n",
    "    outputs=[message_output], \n",
    "    examples=[\n",
    "        \"Explain the Transformer architecture to a layperson\",\n",
    "        \"Explain the Transformer architecture to an aspiring AI engineer\",\n",
    "        ], \n",
    "    flagging_mode=\"never\"\n",
    "    )\n",
    "view.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ccdd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_gpt(prompt):\n",
    "  message= [\n",
    "    {\"role\":\"system\",\"content\":system_message},\n",
    "    {\"role\":'user','content':prompt}\n",
    "  ]\n",
    "  stream = openai.chat.completions.create(\n",
    "    model='gpt-4.1-mini',\n",
    "    messages=message,\n",
    "    stream=True\n",
    "  )\n",
    "\n",
    "  result=\"\"\n",
    "\n",
    "  for chunk in stream:\n",
    "    result+=chunk.choices[0].delta.content or \"\"\n",
    "    yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5533d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_input = gr.Textbox(label=\"Your Message:\",info=\"Enter a message for GPT-4.1-mini\",lines=7)\n",
    "message_output = gr.Markdown(label=\"Response: \")\n",
    "gr.Interface(\n",
    "  fn=stream_gpt,\n",
    "  inputs=[messages_input],\n",
    "  outputs=[message_output],\n",
    "  examples=[\"Exaplin transformers evolution is it the same as 2017 or team have modified it\"],\n",
    "  flagging_mode=\"never\"\n",
    ").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50926806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def claude_response(prompt):\n",
    "  prompt_message = [{\"role\":'user',\"content\":prompt},{\"role\":'system','content':system_message}]\n",
    "\n",
    "  stream = openai.chat.completions.create(\n",
    "    model='gpt-4.1-nano',\n",
    "    messages=prompt_message,\n",
    "    stream=True\n",
    "  )\n",
    "\n",
    "  result = \"\"\n",
    "\n",
    "  for i in stream:\n",
    "    if i is None:\n",
    "      break\n",
    "    delta = i.choices[0].delta\n",
    "    content = getattr(delta,'content',None)\n",
    "    if content:\n",
    "      result+=content\n",
    "    yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb1f845",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_input = gr.Textbox(label=\"Your message: \",info=\"Enter a message for GPT-4.1-mini\",lines=7)\n",
    "\n",
    "message_output = gr.Markdown(label=\"Response: \")\n",
    "\n",
    "view = gr.Interface(\n",
    "  fn=claude_response,\n",
    "  title=\"Claude\",\n",
    "  inputs=[message_input],\n",
    "  outputs=[message_output],\n",
    "  examples=[\n",
    "    \"Exaplin transformers evolution is it the same as 2017 or team have modified it\"\n",
    "  ], flagging_mode=\"never\"\n",
    ").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f79b083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_model(prompt,model):\n",
    "  if model == 'GPT':\n",
    "    result = stream_gpt(prompt)\n",
    "  elif model == 'Claude':\n",
    "    result = claude_response(prompt)\n",
    "  else:\n",
    "    raise ValueError(\"Unknown model\")\n",
    "  yield from result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e517bfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_input = gr.Textbox(label=\"Your message: \",info=\"Enter a message for the LLM\",lines=7)\n",
    "model_selector = gr.Dropdown([\"GPT\",\"Claude\"],label=\"Select Model\")\n",
    "message_output = gr.Markdown(label=\"Response: \")\n",
    "\n",
    "gr.Interface(\n",
    "  fn=stream_model,\n",
    "  title=\"LLMs\",\n",
    "  inputs=[messages_input,model_selector],\n",
    "  outputs=[message_output],\n",
    "  examples = [\n",
    "    [\"Examplain the Transformers\",\"GPT\"],\n",
    "    [\"Exaplain architecture\",\"Claude\"]\n",
    "  ],\n",
    "  flagging_mode = \"never\"\n",
    ").launch()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939a1e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install playwright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da86301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { chromium } from \"playwright\";\n",
    "def scrapper_text():\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58865632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
